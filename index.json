
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"Hello! I am a third-year PhD student in computer science at the University of Washington, advised by Yejin Choi and Noah Smith. My research area is natural language processing, and I am particularly interested in developing algorithms for dataset creation that lead to more robust and reliable models. I am supported by the NSF Graduate Research Fellowship.\nI received my Bachelor’s degree from Northwestern University, majoring in computer science and math. There, I was super fortunate to learn about the world of research through natural language processing and computer audition with Professor Doug Downey, Professor Bryan Pardo, and Dr. Prem Seetharaman.\n","date":1682553600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1682553600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Hello! I am a third-year PhD student in computer science at the University of Washington, advised by Yejin Choi and Noah Smith. My research area is natural language processing, and I am particularly interested in developing algorithms for dataset creation that lead to more robust and reliable models.","tags":null,"title":"Alisa Liu","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature. Slides can be added in a few ways:\nCreate slides using Wowchemy’s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes. Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"https://alisawuffles.github.com/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Alisa Liu","Zhaofeng Wu","Julian Michael","Alane Suhr","Peter West","Alexander Koller","Swabha Swayamdipta","Noah A. Smith","Yejin Choi"],"categories":null,"content":"","date":1682553600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1682553600,"objectID":"b48b43b64ec2bc2af513d17233ee3383","permalink":"https://alisawuffles.github.com/publication/ambient/","publishdate":"2023-04-27T00:00:00Z","relpermalink":"/publication/ambient/","section":"publication","summary":"We build a benchmark to evaluate LM understanding of ambiguity, which is an intrinsic feature of language, and find that the task remains extremely challenging, including for GPT-4","tags":["ambiguity","dataset collection","natural language inference"],"title":"We're Afraid Language Models Aren't Modeling Ambiguity","type":"publication"},{"authors":["Yizhong Wang","Yeganeh Kordi","Swaroop Mishra","Alisa Liu","Noah A. Smith","Daniel Khashabi","Hannaneh Hajishirzi"],"categories":null,"content":"","date":1671580800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671580800,"objectID":"65fd5b50fdcad78d1167e05b9aebb209","permalink":"https://alisawuffles.github.com/publication/self_instruct/","publishdate":"2022-12-21T00:00:00Z","relpermalink":"/publication/self_instruct/","section":"publication","summary":"Large \"instruction-tuned\" language models (finetuned to respond to instructions) have demonstrated a remarkable ability to generalize zero-shot to new tasks. Nevertheless, they depend heavily on human-written instruction data that is limited in quantity, diversity, and creativity, therefore hindering the generality of the tuned model. We introduce Self-Instruct, a framework for improving the instruction-following capabilities of pretrained language models by bootstrapping off its own generations. Our pipeline generates instruction, input, and output samples from a language model, then prunes them before using them to finetune the original model. Applying our method to vanilla GPT3, we demonstrate a 33% absolute improvement over the original model on Super-NaturalInstructions, on par with the performance of InstructGPT_001, which is trained with private user data and human annotations. For further evaluation, we curate a set of expert-written instructions for novel tasks, and show through human evaluation that tuning GPT3 with Self-Instruct outperforms using existing public instruction datasets by a large margin, leaving only a 5% absolute gap behind InstructGPT_001. Self-Instruct provides an almost annotation-free method for aligning pre-trained language models with instructions, and we release our large synthetic dataset to facilitate future studies on instruction tuning.","tags":["text generation","dataset collection","instruction following"],"title":"Self-Instruct: Aligning Language Models with Self-Generated Instructions","type":"publication"},{"authors":["Skyler Hallinan","Alisa Liu","Yejin Choi","Maarten Sap"],"categories":null,"content":"","date":1671494400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671494400,"objectID":"72bd9d47190ac45611b625fb662c3ba5","permalink":"https://alisawuffles.github.com/publication/marco/","publishdate":"2022-12-20T00:00:00Z","relpermalink":"/publication/marco/","section":"publication","summary":"Text detoxification has the potential to mitigate the harms of toxicity by rephrasing text to remove offensive meaning, but subtle toxicity remains challenging to tackle. We introduce MaRCo, a detoxification algorithm that combines controllable generation and text rewriting methods using a Product of Experts with autoencoder language models (LMs). MaRCo uses likelihoods under a non-toxic LM (expert) and a toxic LM (anti-expert) to find candidate words to mask and potentially replace. We evaluate our method on several subtle toxicity and microaggressions datasets, and show that it not only outperforms baselines on automatic metrics, but MaRCo's rewrites are preferred 2.1 × more in human evaluation. Its applicability to instances of subtle toxicity is especially promising, demonstrating a path forward for addressing increasingly elusive online hate.","tags":["text generation","toxicity"],"title":"Detoxifying Text with MaRCo: Controllable Revision with Experts and Anti-Experts","type":"publication"},{"authors":["Alisa Liu","Swabha Swayamdipta","Noah A. Smith","Yejin Choi"],"categories":null,"content":"","date":1642204800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1642204800,"objectID":"756e63fd5afe5ba0196006ae27fe679a","permalink":"https://alisawuffles.github.com/publication/wanli/","publishdate":"2022-01-15T00:00:00Z","relpermalink":"/publication/wanli/","section":"publication","summary":"We introduce a paradigm for dataset creation based on human and machine collaboration, and demonstrate its empirical effectiveness for collecting a new large-scale NLI dataset","tags":["dataset collection","text generation","natural langauge inference"],"title":"WANLI: Worker and AI Collaboration for Natural Language Inference Dataset Creation","type":"publication"},{"authors":["Jiacheng Liu","Alisa Liu","Ximing Lu","Sean Welleck","Peter West","Ronan Le Bras","Yejin Choi","Hannaneh Hajishirzi"],"categories":null,"content":"","date":1640995200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1640995200,"objectID":"0b33cac39a523ad281eceee3b454f54e","permalink":"https://alisawuffles.github.com/publication/knowledge_gen/","publishdate":"2022-01-01T00:00:00Z","relpermalink":"/publication/knowledge_gen/","section":"publication","summary":"Prompting GPT-3 to generate relevant background knowledge improves performance on a variety of commonsense reasoning tasks","tags":["text generation","commonsense reasoning"],"title":"Generated Knowledge Prompting for Commonsense Reasoning","type":"publication"},{"authors":["Alisa Liu","Maarten Sap","Ximing Lu","Swabha Swayamdipta","Chandra Bhagavatula","Noah A. Smith","Yejin Choi"],"categories":null,"content":"","date":1627862400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1627862400,"objectID":"0603c839ecc8847a0334bc6cedb0e026","permalink":"https://alisawuffles.github.com/publication/dexperts/","publishdate":"2021-08-02T00:00:00Z","relpermalink":"/publication/dexperts/","section":"publication","summary":"Steering open-ended text generation toward desired or away from undesired attributes, using expert and anti-expert language models","tags":["text generation","toxicity"],"title":"DExperts: Decoding-Time Controlled Text Generation with Experts and Anti-Experts","type":"publication"},{"authors":["Alisa Liu","Prem Seetharaman","Bryan Pardo"],"categories":null,"content":"","date":1604275200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604275200,"objectID":"5670b4eefae894fde84d28a2990337f4","permalink":"https://alisawuffles.github.com/publication/ensemble/","publishdate":"2020-11-02T00:00:00Z","relpermalink":"/publication/ensemble/","section":"publication","summary":"Ensemble model for audio source separation, using a confidence measure to mediate among domain-specific models","tags":["source separation","deep clustering"],"title":"Model Selection for Deep Audio Source Separation via Clustering Analysis","type":"publication"},{"authors":["Alex Fang","Alisa Liu","Prem Seetharaman","Bryan Pardo"],"categories":null,"content":"","date":1595030400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595030400,"objectID":"2a6c41a4f969a5982c323f6a62c270d4","permalink":"https://alisawuffles.github.com/publication/grading_function/","publishdate":"2020-07-18T00:00:00Z","relpermalink":"/publication/grading_function/","section":"publication","summary":"An automatic, interpretable, and musically-motivated grading function for Bach chorales","tags":["music generation"],"title":"Bach or Mock? A Grading Function for Chorales in the Style of J.S. Bach","type":"publication"},{"authors":["Alisa Liu","Alex Fang","Gaëtan Hadjeres","Prem Seetharaman","Bryan Pardo"],"categories":null,"content":"","date":1595030400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595030400,"objectID":"84858b3d3275032965c11e31f112e34a","permalink":"https://alisawuffles.github.com/publication/aug_gen/","publishdate":"2020-07-18T00:00:00Z","relpermalink":"/publication/aug_gen/","section":"publication","summary":"A generative data augmentation method for music generation systems on a resource-constrained domain","tags":["music generation"],"title":"Incorporating Music Knowledge in Continual Dataset Augmentation for Music Generation","type":"publication"},{"authors":["Alisa Liu"],"categories":null,"content":"I really enjoy making study guides! Here are a couple I’m especially proud of, and I hope they are useful resources for other students.\nEECS 396: Statistical Machine Learning The professor shared the topic being tested by every problem on the final, so I organized course content around it.\nMath 312: Number Theory One of my favorite classes (and subjects) of all time. I shared this with the class and passed it on to many students who would take the course after me. I still hear from people who use it, which makes me really happy.\nMath 320: Real Analysis This class ⁠makes robust everything we know and love from calculus. In this study guide I try to outline approaches to common problems and provide examples of functions with interesting properties.\nMath 307: Applications of Linear Algebra More of a formula sheet than a study guide.\n","date":1573257600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573257600,"objectID":"10648a30886333134259f643769e3276","permalink":"https://alisawuffles.github.com/post/study-guides/","publishdate":"2019-11-09T00:00:00Z","relpermalink":"/post/study-guides/","section":"post","summary":"I really enjoy making study guides! Here are a couple I’m especially proud of, and I hope they are useful resources for other students.\nEECS 396: Statistical Machine Learning The professor shared the topic being tested by every problem on the final, so I organized course content around it.","tags":null,"title":"Study guides from undergrad","type":"post"},{"authors":["Michael Chen","Mike D’Arcy","Alisa Liu","Jared Fernandez","Doug Downey"],"categories":null,"content":"","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559347200,"objectID":"be980448a0cf79ef2ae03d613777bb02","permalink":"https://alisawuffles.github.com/publication/codah/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/publication/codah/","section":"publication","summary":"An adversarially-constructed dataset for common sense QA","tags":["commonsense reasoning","dataset collection"],"title":"CODAH: An Adversarially-Authored Question Answering Dataset for Common Sense","type":"publication"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"e8f8d235e8e7f2efd912bfe865363fc3","permalink":"https://alisawuffles.github.com/project/example/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"d1311ddf745551c9e117aa4bb7e28516","permalink":"https://alisawuffles.github.com/project/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/external-project/","section":"project","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"project"}]